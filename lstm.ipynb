{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('new_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['traffic_volume']\n",
    "X = df.drop(['traffic_volume'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = X.join(y, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(40553, 3, 16) (40553,)\n"
     ]
    }
   ],
   "source": [
    "# choose a number of time steps\n",
    "n_steps =3\n",
    "# convert into input/output\n",
    "X, y = split_sequences(df.values, n_steps)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test splitting\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling input variables\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(x_train)\n",
    "X_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling output variables\n",
    "Y_train = y_train.values.reshape(len(y_train), 1)\n",
    "Y_test = y_test.values.reshape(len(y_test), 1)\n",
    "\n",
    "Y_train = scaler.fit_transform(Y_train)\n",
    "Y_test = scaler.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(x_data, y_data, n_steps):\n",
    "    # prepare the list for the transformed data\n",
    "\tX, y = list(), list()\n",
    "    # loop of the entire data\n",
    "\tfor i in range(len(x_data)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif end_ix > len(x_data):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = x_data[i:end_ix], y_data[end_ix-1]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(28386, 3, 16) (28386, 1)\n"
     ]
    }
   ],
   "source": [
    "# choose a number of time steps\n",
    "n_steps =3\n",
    "# convert into input/output for training set\n",
    "X_train_3D, Y_train_3D = split_sequences(X_train, Y_train, n_steps)\n",
    "print(X_train_3D.shape, Y_train_3D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(12165, 3, 16) (12165, 1)\n"
     ]
    }
   ],
   "source": [
    "# convert into input/output for test set\n",
    "X_test_3D, Y_test_3D = split_sequences(X_test, Y_test, n_steps)\n",
    "print(X_test_3D.shape, Y_test_3D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 16) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 16), dtype=tf.float32, name='lstm_13_input'), name='lstm_13_input', description=\"created by layer 'lstm_13_input'\"), but it was called on an input with incompatible shape (None, 3, 16).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 16) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 16), dtype=tf.float32, name='lstm_13_input'), name='lstm_13_input', description=\"created by layer 'lstm_13_input'\"), but it was called on an input with incompatible shape (None, 3, 16).\n",
      "40/40 [==============================] - ETA: 0s - loss: 0.7904WARNING:tensorflow:Model was constructed with shape (None, 1, 16) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 16), dtype=tf.float32, name='lstm_13_input'), name='lstm_13_input', description=\"created by layer 'lstm_13_input'\"), but it was called on an input with incompatible shape (None, 3, 16).\n",
      "40/40 [==============================] - 6s 45ms/step - loss: 0.7865 - val_loss: 0.3391\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.2835 - val_loss: 0.1569\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 1s 24ms/step - loss: 0.1547 - val_loss: 0.1090\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.1143 - val_loss: 0.0896\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.0945 - val_loss: 0.0849\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0881 - val_loss: 0.0852\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0815 - val_loss: 0.0754\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.0764 - val_loss: 0.0754\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.0736 - val_loss: 0.0752\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.0681 - val_loss: 0.0725\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.0647 - val_loss: 0.0725\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.0600 - val_loss: 0.0755\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0596 - val_loss: 0.0780\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.0621 - val_loss: 0.0694\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0532 - val_loss: 0.0759\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0525 - val_loss: 0.0730\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0483 - val_loss: 0.0726\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0467 - val_loss: 0.0730\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.0443 - val_loss: 0.0708\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.0409 - val_loss: 0.0725\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0401 - val_loss: 0.0724\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 1s 23ms/step - loss: 0.0374 - val_loss: 0.0748\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 1s 22ms/step - loss: 0.0370 - val_loss: 0.0738\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 1s 21ms/step - loss: 0.0356 - val_loss: 0.0745\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "Epoch 00024: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# initialize the neural network based on LSTM\n",
    "model = Sequential()\n",
    "# adding 1st LSTM layer\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(num_steps, num_features)))\n",
    "# adding 2nd LSTM layer\n",
    "model.add(LSTM(units=50, return_sequences=False))\n",
    "# adding dropout\n",
    "model.add(Dropout(0.25))\n",
    "# output layer\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "# compiling the neural network\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
    "\n",
    "#%%time\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=10, verbose=1)\n",
    "rlr = ReduceLROnPlateau(monitor='val_loss',factor=0.5, patience=10, verbose=1)\n",
    "\n",
    "history = model.fit(X_train_3D, Y_train_3D, shuffle=True, epochs=50, callbacks=[es, rlr], validation_split=0.3, verbose=1, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training score = 0.9619683329801219\n",
      "R2 = 0.9287311658429825\n",
      "MAE = 0.17714949717759446\n",
      "RMSE = 0.2638803057735535\n"
     ]
    }
   ],
   "source": [
    "# LSTM prediction\n",
    "LSTM_predTrain = model.predict(X_train_3D)\n",
    "print('training score =',r2_score(Y_train_3D, LSTM_predTrain))\n",
    "LSTM_predTest = model.predict(X_test_3D)\n",
    "print('R2 =',r2_score(LSTM_predTest , Y_test_3D))\n",
    "print('MAE =',mean_absolute_error(LSTM_predTest , Y_test_3D))\n",
    "print('RMSE =',mean_squared_error(LSTM_predTest , Y_test_3D, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.3132216 ],\n",
       "       [0.4336381 ],\n",
       "       [0.38535717],\n",
       "       ...,\n",
       "       [1.3347505 ],\n",
       "       [0.7074195 ],\n",
       "       [1.2235371 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 192
    }
   ],
   "source": [
    "LSTM_predTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(12165, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 181
    }
   ],
   "source": [
    "Y_test[:-2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_length = 720\n",
    "batch_size = 32\n",
    "num_features = x_train.shape[1]\n",
    "train_generator = TimeseriesGenerator(X_train, Y_train, length=win_length, sampling_rate=1, batch_size=batch_size)\n",
    "test_generator = TimeseriesGenerator(X_test, Y_test, length=win_length, sampling_rate=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(128, input_shape= (win_length, num_features), return_sequences=True))\n",
    "model.add(tf.keras.layers.LeakyReLU(alpha=0.5))\n",
    "model.add(tf.keras.layers.LSTM(128, return_sequences=True))\n",
    "model.add(tf.keras.layers.LeakyReLU(alpha=0.5))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.LSTM(64, return_sequences=False))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm (LSTM)                  (None, 720, 128)          74752     \n_________________________________________________________________\nleaky_re_lu (LeakyReLU)      (None, 720, 128)          0         \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 720, 128)          131584    \n_________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)    (None, 720, 128)          0         \n_________________________________________________________________\ndropout (Dropout)            (None, 720, 128)          0         \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 64)                49408     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 64)                0         \n_________________________________________________________________\ndense (Dense)                (None, 1)                 65        \n=================================================================\nTotal params: 255,809\nTrainable params: 255,809\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "865/865 [==============================] - 1462s 2s/step - loss: 1.0098 - mean_absolute_error: 0.8796 - val_loss: 1.0150 - val_mean_absolute_error: 0.8835\n",
      "Epoch 2/50\n",
      "865/865 [==============================] - 1432s 2s/step - loss: 1.0078 - mean_absolute_error: 0.8795 - val_loss: 1.0144 - val_mean_absolute_error: 0.8840\n",
      "Epoch 3/50\n",
      "865/865 [==============================] - 1457s 2s/step - loss: 1.0074 - mean_absolute_error: 0.8793 - val_loss: 1.0150 - val_mean_absolute_error: 0.8838\n",
      "Epoch 4/50\n",
      "865/865 [==============================] - 1566s 2s/step - loss: 1.0069 - mean_absolute_error: 0.8793 - val_loss: 1.0148 - val_mean_absolute_error: 0.8841\n",
      "Epoch 5/50\n",
      "865/865 [==============================] - 1423s 2s/step - loss: 1.0065 - mean_absolute_error: 0.8791 - val_loss: 1.0155 - val_mean_absolute_error: 0.8844\n",
      "Epoch 6/50\n",
      "865/865 [==============================] - 1357s 2s/step - loss: 1.0052 - mean_absolute_error: 0.8782 - val_loss: 1.0165 - val_mean_absolute_error: 0.8844\n",
      "Epoch 7/50\n",
      "865/865 [==============================] - 1627s 2s/step - loss: 1.0035 - mean_absolute_error: 0.8774 - val_loss: 1.0203 - val_mean_absolute_error: 0.8849\n",
      "Epoch 8/50\n",
      "865/865 [==============================] - 1577s 2s/step - loss: 0.9983 - mean_absolute_error: 0.8741 - val_loss: 1.0273 - val_mean_absolute_error: 0.8851\n",
      "Epoch 9/50\n",
      "865/865 [==============================] - 1512s 2s/step - loss: 0.9884 - mean_absolute_error: 0.8676 - val_loss: 1.0369 - val_mean_absolute_error: 0.8871\n",
      "Epoch 10/50\n",
      "865/865 [==============================] - 1405s 2s/step - loss: 0.9774 - mean_absolute_error: 0.8610 - val_loss: 1.0703 - val_mean_absolute_error: 0.8959\n",
      "Epoch 11/50\n",
      "865/865 [==============================] - 1432s 2s/step - loss: 0.9580 - mean_absolute_error: 0.8493 - val_loss: 1.0980 - val_mean_absolute_error: 0.9018\n",
      "Epoch 12/50\n",
      "865/865 [==============================] - 1378s 2s/step - loss: 0.9314 - mean_absolute_error: 0.8333 - val_loss: 1.1436 - val_mean_absolute_error: 0.9156\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
    "\n",
    "model.compile(loss=tf.losses.MeanSquaredError(), optimizer=tf.optimizers.Adam(), metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "history = model.fit_generator(train_generator, epochs=50, validation_data=test_generator, shuffle=False, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1.1435537338256836, 0.915569543838501]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "model.evaluate_generator(test_generator, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(12167, 17)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "X_test[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.80260895,  0.17137926,  0.74414374, ..., -0.36271527,\n",
       "        -1.10607761, -0.49288576],\n",
       "       [ 0.03984344,  0.17137926,  1.0751205 , ..., -0.07458518,\n",
       "         1.20996275, -0.49288576],\n",
       "       [-0.36083386,  0.17137926,  0.66235502, ...,  0.06947987,\n",
       "         0.4379493 , -0.49288576],\n",
       "       ...,\n",
       "       [ 0.71006728,  0.17137926,  0.63713046, ..., -0.50678032,\n",
       "         0.4379493 , -0.49288576],\n",
       "       [ 0.75413818,  0.17137926,  1.39157403, ...,  0.06947987,\n",
       "         0.4379493 , -0.49288576],\n",
       "       [-0.44551345,  0.17137926,  0.76172449, ...,  0.64574006,\n",
       "         0.4379493 ,  2.23454117]])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "X_test[:,0:][win_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = pd.concat([pd.DataFrame(predictions), pd.DataFrame(X_test[:,0:][win_length:]), pd.DataFrame(Y_test[:,0:][win_length:])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MAE = 0.914038168519139\nRMSE = 1.0680035000451993\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#print('R2 =',r2_score(predictions , Y_test[0:11447]))\n",
    "print('MAE =',mean_absolute_error(predictions , Y_test[0:11447]))\n",
    "print('RMSE =',mean_squared_error(predictions , Y_test[0:11447], squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(40553, 3, 16) (40553,)\n"
     ]
    }
   ],
   "source": [
    "# choose a number of time steps\n",
    "n_steps =3\n",
    "# convert into input/output\n",
    "X, y = split_sequences(df.values, n_steps)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'holiday', 'temp', 'rain_1h', 'snow_1h', 'clouds_all',\n",
       "       'weather_main', 'weather_description', 'traffic_volume', 'year',\n",
       "       'month', 'day', 'dayofyear', 'weekofyear', 'dayofweek', 'hour',\n",
       "       'is_weekend', 'peak_hr'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   holiday    temp  rain_1h  snow_1h  clouds_all  weather_main  \\\n",
       "0      900  288.28      0.0      0.0          40            40   \n",
       "1      900  289.36      0.0      0.0          75            40   \n",
       "2      900  289.58      0.0      0.0          90            40   \n",
       "3      900  290.13      0.0      0.0          90            40   \n",
       "4      900  291.14      0.0      0.0          75            40   \n",
       "\n",
       "   weather_description  traffic_volume  year  month  day  dayofyear  \\\n",
       "0                   24            5545  2012     10    2        276   \n",
       "1                    2            4516  2012     10    2        276   \n",
       "2                   19            4767  2012     10    2        276   \n",
       "3                   19            5026  2012     10    2        276   \n",
       "4                    2            4918  2012     10    2        276   \n",
       "\n",
       "   weekofyear  dayofweek  hour  is_weekend  peak_hr  \n",
       "0          40          1     9         5.0      1.0  \n",
       "1          40          1    10         5.0      1.0  \n",
       "2          40          1    11         5.0      1.0  \n",
       "3          40          1    12         5.0      1.0  \n",
       "4          40          1    13         5.0      1.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>holiday</th>\n      <th>temp</th>\n      <th>rain_1h</th>\n      <th>snow_1h</th>\n      <th>clouds_all</th>\n      <th>weather_main</th>\n      <th>weather_description</th>\n      <th>traffic_volume</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>dayofyear</th>\n      <th>weekofyear</th>\n      <th>dayofweek</th>\n      <th>hour</th>\n      <th>is_weekend</th>\n      <th>peak_hr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>900</td>\n      <td>288.28</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40</td>\n      <td>40</td>\n      <td>24</td>\n      <td>5545</td>\n      <td>2012</td>\n      <td>10</td>\n      <td>2</td>\n      <td>276</td>\n      <td>40</td>\n      <td>1</td>\n      <td>9</td>\n      <td>5.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>900</td>\n      <td>289.36</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>75</td>\n      <td>40</td>\n      <td>2</td>\n      <td>4516</td>\n      <td>2012</td>\n      <td>10</td>\n      <td>2</td>\n      <td>276</td>\n      <td>40</td>\n      <td>1</td>\n      <td>10</td>\n      <td>5.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>900</td>\n      <td>289.58</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>90</td>\n      <td>40</td>\n      <td>19</td>\n      <td>4767</td>\n      <td>2012</td>\n      <td>10</td>\n      <td>2</td>\n      <td>276</td>\n      <td>40</td>\n      <td>1</td>\n      <td>11</td>\n      <td>5.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>900</td>\n      <td>290.13</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>90</td>\n      <td>40</td>\n      <td>19</td>\n      <td>5026</td>\n      <td>2012</td>\n      <td>10</td>\n      <td>2</td>\n      <td>276</td>\n      <td>40</td>\n      <td>1</td>\n      <td>12</td>\n      <td>5.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>900</td>\n      <td>291.14</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>75</td>\n      <td>40</td>\n      <td>2</td>\n      <td>4918</td>\n      <td>2012</td>\n      <td>10</td>\n      <td>2</td>\n      <td>276</td>\n      <td>40</td>\n      <td>1</td>\n      <td>13</td>\n      <td>5.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8111\n"
     ]
    }
   ],
   "source": [
    "for i in range(16,10000):\n",
    "    if 32444 % i == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}